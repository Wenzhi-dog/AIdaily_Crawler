# Python爬虫项目技术文档

## 项目简介  
本项目旨在爬取新浪科技上指定日期发布的与AI相关的新闻，筛选关键词包括一些AI领域人物的名字（如奥特曼、马斯克等）。爬取结果以JSON文件存储，并下载相关的新闻图片至本地。

---

## 功能需求  

### 爬取目标  
1. **目标网站**：  
   - 新浪科技  

2. **关键词筛选**：  
   - 与AI相关的词汇  
   - AI领域人物（如奥特曼、马斯克等）  

3. **日期格式**：  
   - 日期格式为`yyyy-mm-dd`，仅爬取指定日期的新闻。  

4. **输出格式**：  
   - 将爬取到的新闻信息以JSON文件存储，文件命名格式为`yyyy-mm-dd.json`，字段包括：  
     - `_id`：新闻唯一标识符  
     - `title`：新闻标题  
     - `brief`：新闻简介，如无简介则使用全文第一句话  
     - `content`：新闻全文  
     - `createTime`：发布时间  
     - `url`：新闻具体地址  
     - `imageUrl`：新闻图片的URL  
     - `isRecommend`：推荐标记，默认为`false`  

5. **图片下载**：  
   - 将新闻内的图片下载并保存在本地，目录结构如下：  
     ```
     /images/yyyy-mm-dd/
     ```

---

## 技术要求  

1. **去重**：  
   - 使用新闻的标题或URL作为唯一标识，避免重复爬取同一条新闻。  

2. **日志记录**：  
   - 实时打印爬取进度，并将日志存储在本地文件中（如`log.txt`）。  

3. **遵守`robots.txt`规则**：  
   - 确保爬虫行为符合目标网站的爬取限制。  

4. **网络异常处理**：  
   - 设置重试机制（如3次重试），并在日志中记录失败原因。  

5. **编码规范**：  
   - 使用Python编写，代码注释清晰，遵循PEP 8编码规范。  

---

## 开发步骤  

### 1. 环境搭建  
1. 安装必要的Python库：  
   - requests  
   - beautifulsoup4  
   - lxml  
   - logging  

2. 目录结构初始化：  
   ```
   /project-root/
     ├── main.py               # 主程序入口
     ├── utils.py              # 工具函数
     ├── requirements.txt      # 项目依赖
     ├── images/               # 保存图片
     ├── logs/                 # 保存日志
     ├── yyyy-mm-dd.json       # 爬取结果（示例）
   ```  

---

### 2. 程序流程  

1. **输入日期和关键词**：从用户输入获取指定的日期。  
2. **解析目标网站**：爬取新浪科技。  
3. **筛选新闻**：根据关键词匹配标题或内容。  
4. **提取内容**：确保生成完整的JSON字段（如`brief`自动填充第一句话）。  
5. **下载图片**：保存到本地指定目录。  
6. **保存结果**：输出为JSON文件，命名为`yyyy-mm-dd.json`。  
7. **日志记录**：记录爬取过程及异常。  

---

## 输出格式  

最终结果保存为JSON文件，格式如下：  
```json
[
    {
        "_id": "12345",
        "title": "AI技术在未来的应用",
        "brief": "这是新闻的第一句话。",
        "content": "这是新闻的全文内容。",
        "createTime": "2024-11-14T10:00:00",
        "url": "https://example.com/news/12345",
        "imageUrl": "https://example.com/image1.jpg",
        "isRecommend": false
    }
]
```